import json
from copy import deepcopy
from itertools import zip_longest
from pathlib import Path
from typing import Any

import pytest

from mex.common.models import EXTRACTED_MODEL_CLASSES_BY_NAME
from mex.common.transform import dromedary_to_kebab, kebab_to_camel
from mex.common.types.identifier import MEX_ID_PATTERN

# TODO: find a cleaner way to get to the mex-model JSON schemas
SPECIFIED_SCHEMA_PATH = Path(".venv", "src", "mex-model", "schema", "entities")

GENERATED_SCHEMAS = dict(
    sorted(
        {
            name.removeprefix("Extracted"): model.model_json_schema(
                ref_template="/schema/fields/{model}"
            )
            for name, model in EXTRACTED_MODEL_CLASSES_BY_NAME.items()
        }.items()
    )
)
SPECIFIED_SCHEMAS = dict(
    sorted(
        {
            schema["title"].replace(" ", ""): schema
            for file_name in SPECIFIED_SCHEMA_PATH.glob("*.json")
            if (schema := json.load(open(file_name, encoding="utf-8")))
            and not schema["title"].startswith("Concept")
        }.items()
    )
)
ENTITY_TYPES_AND_FIELD_NAMES_BY_FQN = {
    f"{entity_type}.{field_name}": (entity_type, field_name)
    for entity_type, schema in SPECIFIED_SCHEMAS.items()
    for field_name in schema["properties"]
}


def test_entity_types_match_spec() -> None:
    assert list(GENERATED_SCHEMAS) == list(SPECIFIED_SCHEMAS)


@pytest.mark.parametrize(
    ("generated", "specified"),
    zip_longest(GENERATED_SCHEMAS.values(), SPECIFIED_SCHEMAS.values()),
    ids=GENERATED_SCHEMAS,
)
def test_field_names_match_spec(
    generated: dict[str, Any], specified: dict[str, Any]
) -> None:
    assert set(generated["properties"]) == set(specified["properties"])


@pytest.mark.parametrize(
    ("generated", "specified"),
    zip_longest(GENERATED_SCHEMAS.values(), SPECIFIED_SCHEMAS.values()),
    ids=GENERATED_SCHEMAS,
)
def test_required_fields_match_spec(
    generated: dict[str, Any], specified: dict[str, Any]
) -> None:
    assert set(generated["required"]) == set(specified["required"])


def deduplicate_dicts(dicts: list[dict[str, Any]]) -> list[dict[str, Any]]:
    return [json.loads(s) for s in dict.fromkeys(json.dumps(d) for d in dicts)]


def prepare_field(field: str, obj: list[Any] | dict[str, Any]) -> None:
    # prepare each item in a list
    if isinstance(obj, list):
        for item in obj:
            prepare_field(field, item)
        obj[:] = [item for item in obj if item]
        return

    # discard annotations that we fully ignore because they have no use case yet
    obj.pop("sameAs", None)  # only in spec
    obj.pop("subPropertyOf", None)  # only in spec
    obj.pop("description", None)  # only in model (mostly implementation hints)

    # pop annotations that we don't compare directly but use for other comparisons
    title = obj.pop("title", "")  # only in model (autogenerated by pydantic)
    use_scheme = obj.pop("useScheme", "")  # only in spec (needed to select vocabulary)

    # ignore differences between dates and datetimes
    # (we only have `Timestamp` as a date-time implementation, but no type for `date`,
    # but we might/should add that in the future)
    if obj.get("format") in ("date", "date-time"):
        obj.pop("examples", None)
        obj.pop("pattern", None)
        obj["format"] = "date-time"

    # align reference paths
    if obj.get("pattern") == MEX_ID_PATTERN:
        obj.pop("pattern")
        obj.pop("type", None)
        if field in ("identifier", "stableTargetId"):
            obj["$ref"] = "/schema/fields/identifier"
        else:
            title = dromedary_to_kebab(title.removesuffix("ID"))
            obj["$ref"] = f"/schema/entities/{title}#/identifier"

    # align concept/enum annotations
    # (the spec uses the `useScheme` annotation to specify a vocabulary and the models
    # use enums that are )
    if obj.get("$ref") == "/schema/entities/concept#/identifier":
        name = kebab_to_camel(use_scheme.removeprefix("https://mex.rki.de/item/"))
        obj["$ref"] = f"/schema/fields/{name}"

    # recurse into the field definitions for array items
    if obj.get("type") == "array":
        prepare_field(field, obj["items"])

    for quantifier in {"anyOf", "allOf"} & set(obj):
        # prepare choices
        prepare_field(field, obj[quantifier])

        # deduplicate items, used for date/times
        obj[quantifier] = deduplicate_dicts(obj[quantifier])

        # collapse non-choices
        if len(obj[quantifier]) == 1:
            obj.update(obj.pop(quantifier)[0])


@pytest.mark.parametrize(
    ("entity_type", "field_name"),
    ENTITY_TYPES_AND_FIELD_NAMES_BY_FQN.values(),
    ids=ENTITY_TYPES_AND_FIELD_NAMES_BY_FQN.keys(),
)
def test_field_defs_match_spec(entity_type: str, field_name: str) -> None:
    specified_properties = SPECIFIED_SCHEMAS[entity_type]["properties"]
    generated_properties = GENERATED_SCHEMAS[entity_type]["properties"]
    specified = deepcopy(specified_properties[field_name])
    generated = deepcopy(generated_properties[field_name])

    prepare_field(field_name, specified)
    prepare_field(field_name, generated)

    assert (
        generated == specified
    ), f"""
{entity_type}.{field_name}

specified:
{json.dumps(specified_properties[field_name], indent=4, sort_keys=True)}

generated:
{json.dumps(generated_properties[field_name], indent=4, sort_keys=True)}
"""
